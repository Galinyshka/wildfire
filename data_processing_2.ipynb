{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Разбивка снимков на более крупные сектора для скачивания синоптических данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Чтение данных\n",
    "ds = pd.read_csv('dataset_veg_index.csv', index_col=0)\n",
    "\n",
    "def calculate_sector_dimensions(ds):\n",
    "    \"\"\"Создает словарь с размерами (x, y) для каждого уникального sector_id.\"\"\"\n",
    "    sector_dict = {}\n",
    "    for id in ds.sector_id.unique():\n",
    "        x = ds[ds.sector_id == id].lon.nunique()\n",
    "        y = ds[ds.sector_id == id].lat.nunique()\n",
    "        sector_dict[id] = (x, y)\n",
    "    return sector_dict\n",
    "\n",
    "def get_macro_px_id(M, N, sector_x, sector_y, cell_size):\n",
    "    \"\"\"Вычисляет macro_px_id на основе размеров и положения.\"\"\"\n",
    "    x_cells = (M + cell_size - 1) // cell_size\n",
    "    y_cells = (N + cell_size - 1) // cell_size\n",
    "    \n",
    "    cell_id = sector_x // cell_size + (sector_y // cell_size) * x_cells\n",
    "    return cell_id\n",
    "\n",
    "def get_sector_idx(ds):\n",
    "    \"\"\"Добавляет в DataFrame столбец sector_idx.\"\"\"\n",
    "    ds['sector_idx'] = 0\n",
    "    set_unique = set()\n",
    "    counter = 0\n",
    "    for idx, row in ds.iterrows():\n",
    "        uniq = f\"{row.date}_{row.sector_id}\"\n",
    "        if uniq not in set_unique:\n",
    "            counter = 0\n",
    "            set_unique.add(uniq)\n",
    "        ds.loc[idx, 'sector_idx'] = counter\n",
    "        counter += 1\n",
    "    return ds\n",
    "\n",
    "def get_sector_xy(idx, M, N):\n",
    "    \"\"\"Возвращает координаты сектора (x, y) на основе индекса.\"\"\"\n",
    "    sector_x = idx % M\n",
    "    sector_y = idx // M\n",
    "    return sector_x, sector_y\n",
    "\n",
    "def is_center(sector_x, sector_y, cell_size):\n",
    "    \"\"\"Создает булевый флаг, указывающий, является ли сектор центральным.\"\"\"\n",
    "    return (sector_x % cell_size == cell_size // 2) and (sector_y % cell_size == cell_size // 2)\n",
    "\n",
    "def process_dataset(ds, sector_dict, cell_size=19): # cell_size - размер новой ячейки\n",
    "    \"\"\"Обрабатывает DataFrame, добавляя столбцы 'macro_px_id' и 'is_center'.\"\"\"\n",
    "    ds['macro_px_id'] = 0\n",
    "    ds['is_center'] = 0\n",
    "    \n",
    "    for idx, row in ds.iterrows():\n",
    "        sector_id = row.sector_id\n",
    "        M, N = sector_dict[sector_id]\n",
    "        sector_x, sector_y = get_sector_xy(row.sector_idx, M, N)\n",
    "        ds.loc[idx, 'macro_px_id'] = get_macro_px_id(M, N, sector_x, sector_y, cell_size)\n",
    "        ds.loc[idx, 'is_center'] = int(is_center(sector_x, sector_y, cell_size))\n",
    "    \n",
    "    return ds\n",
    "\n",
    "# Основной блок выполнения\n",
    "sector_dict = calculate_sector_dimensions(ds)\n",
    "ds = get_sector_idx(ds)\n",
    "ds = process_dataset(ds, sector_dict)\n",
    "\n",
    "# Сохранение результата\n",
    "ds.to_csv('dataset_veg_index_cell.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Получение данных о погоде с помощью API OpenWeatherMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openmeteo_requests\n",
    "\n",
    "import requests_cache\n",
    "import pandas as pd\n",
    "from retry_requests import retry\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def get_wether_by_api(df):\n",
    "    # df columns: date, lat, lon!!!\n",
    "    \n",
    "    # Создаем список с начальными датами, которые на неделю раньше\n",
    "    start_dates = pd.to_datetime(df['date']) - pd.Timedelta(weeks=1)\n",
    "\n",
    "    # Преобразуем начальные даты в строки в формате 'YYYY-MM-DD'\n",
    "    start_date_list = start_dates.dt.strftime('%Y-%m-%d').tolist()\n",
    "\n",
    "    # Преобразуем остальные столбцы в списки\n",
    "    lat_list = df['lat'].tolist()\n",
    "    lon_list = df['lon'].tolist()\n",
    "    end_date_list = df['date'].tolist()  \n",
    "    sector_id = df['sector_id'].tolist()\n",
    "    macro_px_id = df['macro_px_id'].tolist()\n",
    "    \n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "    retry_session = retry(cache_session, retries = 5, backoff_factor = 0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "    # Инициализируем пустые списки для хранения промежуточных DataFrame\n",
    "    final_datasets = []\n",
    "    \n",
    "    pbar = tqdm(total=len(lat_list)//80, desc=\"Processing data\", unit=\"locations\", )\n",
    "    \n",
    "    for i in range(0, len(lat_list), 80):\n",
    "        final_dataframes = []\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": lat_list[i:i+80],\n",
    "            \"longitude\": lon_list[i:i+80],\n",
    "            \"start_date\": start_date_list[i:i+80],\n",
    "            \"end_date\": end_date_list[i:i+80],\n",
    "            \"hourly\": \"relative_humidity_2m\",\n",
    "            \"daily\": [\"temperature_2m_mean\", \"rain_sum\", \"wind_speed_10m_max\"],\n",
    "            \"timezone\": \"auto\"\n",
    "        }\n",
    "        \n",
    "        batch_sector_id = sector_id[i:i+80]\n",
    "        batch_macro_px_id = macro_px_id[i:i+80]\n",
    "        responses = openmeteo.weather_api(url, params=params)\n",
    "        \n",
    "        # Итерация по всем ответам в списке responses\n",
    "        assert len(responses) == len(batch_sector_id) == len(batch_macro_px_id)\n",
    "        for response, sector, px in zip(responses, batch_sector_id, batch_macro_px_id):\n",
    "            \n",
    "            # Извлекаем координаты\n",
    "            latitude = response.Latitude()\n",
    "            longitude = response.Longitude()\n",
    "            \n",
    "            # Получаем и обрабатываем почасовые данные\n",
    "            hourly = response.Hourly()\n",
    "            hourly_relative_humidity_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "\n",
    "            hourly_data = {\n",
    "                \"date\": pd.date_range(\n",
    "                    start=pd.to_datetime(hourly.Time(), unit=\"s\", utc=True),\n",
    "                    end=pd.to_datetime(hourly.TimeEnd(), unit=\"s\", utc=True),\n",
    "                    freq=pd.Timedelta(seconds=hourly.Interval()),\n",
    "                    inclusive=\"right\"\n",
    "                ),\n",
    "                \"relative_humidity_2m\": hourly_relative_humidity_2m\n",
    "            }\n",
    "            \n",
    "            hourly_dataframe = pd.DataFrame(data=hourly_data)\n",
    "            hourly_dataframe[\"lat\"] = latitude\n",
    "            hourly_dataframe[\"lon\"] = longitude\n",
    "            \n",
    "            \n",
    "            # Группируем по дате и рассчитываем среднее значение влажности за день\n",
    "            hourly_dataframe = hourly_dataframe.groupby([\"date\", \"lat\", \"lon\"]).agg({\n",
    "                \"relative_humidity_2m\": \"mean\"\n",
    "            }).reset_index()\n",
    "            \n",
    "            # Получаем и обрабатываем ежедневные данные\n",
    "            daily = response.Daily()\n",
    "            daily_temperature_2m_mean = daily.Variables(0).ValuesAsNumpy()\n",
    "            daily_rain_sum = daily.Variables(1).ValuesAsNumpy()\n",
    "            daily_wind_speed_10m_max = daily.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "            daily_data = {\n",
    "                \"date\": pd.date_range(\n",
    "                    start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "                    end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "                    freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "                    inclusive=\"right\"\n",
    "                ),\n",
    "                \"temperature_2m_mean\": daily_temperature_2m_mean,\n",
    "                \"rain_sum\": daily_rain_sum,\n",
    "                \"wind_speed_10m_max\": daily_wind_speed_10m_max\n",
    "            }\n",
    "            \n",
    "            daily_dataframe = pd.DataFrame(data=daily_data)\n",
    "            daily_dataframe[\"lat\"] = latitude\n",
    "            daily_dataframe[\"lon\"] = longitude\n",
    "            daily_dataframe[\"sector_id\"] = sector\n",
    "            daily_dataframe[\"macro_px_id\"] = px\n",
    "            \n",
    "            # Объединяем почасовые и ежедневные данные по дате и координатам\n",
    "            merged_dataframe = pd.merge(hourly_dataframe, daily_dataframe, on=[\"date\", \"lat\", \"lon\"], how=\"inner\")\n",
    "            \n",
    "            # Добавляем объединенный DataFrame в список финальных DataFrame\n",
    "            final_dataframes.append(merged_dataframe)\n",
    "\n",
    "        # Объединяем все DataFrame из списка в один финальный DataFrame\n",
    "        final_dataframe = pd.concat(final_dataframes, ignore_index=True)\n",
    "        \n",
    "        final_datasets.append(final_dataframe)\n",
    "        \n",
    "        # Задержка в 6 секунды между запросами к API для предотвращения блокировки IP-адреса сервером Open-Meteo API \n",
    "        time.sleep(10)\n",
    "        pbar.update(1)\n",
    "        \n",
    "    # Объединяем все финальные DataFrame в один общий DataFrame\n",
    "    final_dataset = pd.concat(final_datasets, ignore_index=True)\n",
    "    \n",
    "    return final_dataset\n",
    "\n",
    "# Читаем данные из файла\n",
    "df = pd.read_csv('dataset_veg_index_cell.csv')\n",
    "\n",
    "# Оставляем только центральные ячейки\n",
    "df_central = df[df.is_center == 1].reset_index(drop=True)\n",
    "\n",
    "# Вызываем функцию get_wether_by_api и сохраняем результат в переменную res\n",
    "res = get_wether_by_api(df_central)\n",
    "\n",
    "# Обрабатываем результат\n",
    "res.date = res.date.dt.strftime('%Y-%m-%d')\n",
    "res.drop(columns=['lat', 'lon'], inplace=True)\n",
    "res.to_csv('weather.csv', index=False)\n",
    "\n",
    "# Объединяем исходный DataFrame с полученными данными о погоде\n",
    "final_df = pd.merge(df, res, on=['sector_id', 'macro_px_id'], how='left', suffixes=('_init', '_weather'))\n",
    "\n",
    "# Обработка датасета\n",
    "final_df.rename(columns={'date_init': 'date'}, inplace=True)\n",
    "final_df.drop(columns=['sector_idx', 'macro_px_id', 'is_center'], inplace=True)\n",
    "final_df.dropna(inplace=True)\n",
    "\n",
    "# Запиём полученный DataFrame в файл\n",
    "final_df.to_csv('dataset_veg_index_cell_weather.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
